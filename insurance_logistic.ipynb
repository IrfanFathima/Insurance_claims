{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,Ridge\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,precision_score,recall_score,f1_score,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import  PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>17-10-2014</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>27-06-2006</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>6/9/2000</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>25-05-1990</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>6/6/2014</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>941851</td>\n",
       "      <td>16-07-1991</td>\n",
       "      <td>OH</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1310.80</td>\n",
       "      <td>0</td>\n",
       "      <td>431289</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>87200</td>\n",
       "      <td>17440</td>\n",
       "      <td>8720</td>\n",
       "      <td>61040</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Accord</td>\n",
       "      <td>2006</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>285</td>\n",
       "      <td>41</td>\n",
       "      <td>186934</td>\n",
       "      <td>5/1/2014</td>\n",
       "      <td>IL</td>\n",
       "      <td>100/300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1436.79</td>\n",
       "      <td>0</td>\n",
       "      <td>608177</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>108480</td>\n",
       "      <td>18080</td>\n",
       "      <td>18080</td>\n",
       "      <td>72320</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>2015</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>130</td>\n",
       "      <td>34</td>\n",
       "      <td>918516</td>\n",
       "      <td>17-02-2003</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>500</td>\n",
       "      <td>1383.49</td>\n",
       "      <td>3000000</td>\n",
       "      <td>442797</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>67500</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500</td>\n",
       "      <td>52500</td>\n",
       "      <td>Suburu</td>\n",
       "      <td>Impreza</td>\n",
       "      <td>1996</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>458</td>\n",
       "      <td>62</td>\n",
       "      <td>533940</td>\n",
       "      <td>18-11-2011</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1356.92</td>\n",
       "      <td>5000000</td>\n",
       "      <td>441714</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>46980</td>\n",
       "      <td>5220</td>\n",
       "      <td>5220</td>\n",
       "      <td>36540</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A5</td>\n",
       "      <td>1998</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>456</td>\n",
       "      <td>60</td>\n",
       "      <td>556080</td>\n",
       "      <td>11/11/1996</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>766.19</td>\n",
       "      <td>0</td>\n",
       "      <td>612260</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>5060</td>\n",
       "      <td>460</td>\n",
       "      <td>920</td>\n",
       "      <td>3680</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                   328   48         521585       17-10-2014           OH   \n",
       "1                   228   42         342868       27-06-2006           IN   \n",
       "2                   134   29         687698         6/9/2000           OH   \n",
       "3                   256   41         227811       25-05-1990           IL   \n",
       "4                   228   44         367455         6/6/2014           IL   \n",
       "..                  ...  ...            ...              ...          ...   \n",
       "995                   3   38         941851       16-07-1991           OH   \n",
       "996                 285   41         186934         5/1/2014           IL   \n",
       "997                 130   34         918516       17-02-2003           OH   \n",
       "998                 458   62         533940       18-11-2011           IL   \n",
       "999                 456   60         556080       11/11/1996           OH   \n",
       "\n",
       "    policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0      250/500               1000                1406.91               0   \n",
       "1      250/500               2000                1197.22         5000000   \n",
       "2      100/300               2000                1413.14         5000000   \n",
       "3      250/500               2000                1415.74         6000000   \n",
       "4     500/1000               1000                1583.91         6000000   \n",
       "..         ...                ...                    ...             ...   \n",
       "995   500/1000               1000                1310.80               0   \n",
       "996    100/300               1000                1436.79               0   \n",
       "997    250/500                500                1383.49         3000000   \n",
       "998   500/1000               2000                1356.92         5000000   \n",
       "999    250/500               1000                 766.19               0   \n",
       "\n",
       "     insured_zip  ... witnesses police_report_available total_claim_amount  \\\n",
       "0         466132  ...         2                     YES              71610   \n",
       "1         468176  ...         0                       ?               5070   \n",
       "2         430632  ...         3                      NO              34650   \n",
       "3         608117  ...         2                      NO              63400   \n",
       "4         610706  ...         1                      NO               6500   \n",
       "..           ...  ...       ...                     ...                ...   \n",
       "995       431289  ...         1                       ?              87200   \n",
       "996       608177  ...         3                       ?             108480   \n",
       "997       442797  ...         3                     YES              67500   \n",
       "998       441714  ...         1                     YES              46980   \n",
       "999       612260  ...         3                       ?               5060   \n",
       "\n",
       "    injury_claim property_claim  vehicle_claim   auto_make auto_model  \\\n",
       "0           6510          13020          52080        Saab        92x   \n",
       "1            780            780           3510    Mercedes       E400   \n",
       "2           7700           3850          23100       Dodge        RAM   \n",
       "3           6340           6340          50720   Chevrolet      Tahoe   \n",
       "4           1300            650           4550      Accura        RSX   \n",
       "..           ...            ...            ...         ...        ...   \n",
       "995        17440           8720          61040       Honda     Accord   \n",
       "996        18080          18080          72320  Volkswagen     Passat   \n",
       "997         7500           7500          52500      Suburu    Impreza   \n",
       "998         5220           5220          36540        Audi         A5   \n",
       "999          460            920           3680    Mercedes       E400   \n",
       "\n",
       "    auto_year fraud_reported  \n",
       "0        2004              Y  \n",
       "1        2007              Y  \n",
       "2        2007              N  \n",
       "3        2014              Y  \n",
       "4        2009              N  \n",
       "..        ...            ...  \n",
       "995      2006              N  \n",
       "996      2015              N  \n",
       "997      1996              N  \n",
       "998      1998              N  \n",
       "999      2007              N  \n",
       "\n",
       "[1000 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df = pd.read_csv(\"insurance_claims.csv\")\n",
    "insurance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insurance_df.replace({'Y':1,'N':0},inplace = True)\n",
    "#insurance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df[\"fraud_reported\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['months_as_customer',\n",
       " 'age',\n",
       " 'policy_number',\n",
       " 'policy_deductable',\n",
       " 'policy_annual_premium',\n",
       " 'umbrella_limit',\n",
       " 'insured_zip',\n",
       " 'capital-gains',\n",
       " 'capital-loss',\n",
       " 'incident_hour_of_the_day',\n",
       " 'number_of_vehicles_involved',\n",
       " 'bodily_injuries',\n",
       " 'witnesses',\n",
       " 'total_claim_amount',\n",
       " 'injury_claim',\n",
       " 'property_claim',\n",
       " 'vehicle_claim',\n",
       " 'auto_year']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = []\n",
    "con_cols = []\n",
    "for col in insurance_df.columns:\n",
    "    if insurance_df[col].dtype =='object':\n",
    "        cat_cols.append(col)\n",
    "    else:\n",
    "        con_cols.append(col)\n",
    "cat_cols\n",
    "con_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding correlated columns with categorical output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['N', 'Y'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df['fraud_reported'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'property_claim'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "def anova(col): # col is continous variable\n",
    "    categories_list = list(insurance_df['fraud_reported'].value_counts().index)\n",
    "    result = f_oneway(*(insurance_df[insurance_df['fraud_reported']==category][col] for category in categories_list ))\n",
    "    if result[1] < 0.05:\n",
    "        return col\n",
    "anova('property_claim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continous columns correlated with fraud_reported: [None, None, None, None, None, None, None, None, None, None, None, None, None, 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim', None]\n"
     ]
    }
   ],
   "source": [
    "corr_cols = []\n",
    "for col in con_cols:\n",
    "    corr_cols.append(anova(col))\n",
    "print ('continous columns correlated with fraud_reported:', corr_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P-Value is ', 0.6474289700890913)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "def anova(col): # col is continous variable\n",
    "    categories_list = list(insurance_df['fraud_reported'].value_counts().index)\n",
    "    result = f_oneway(*(insurance_df[insurance_df['fraud_reported']==category][col] for category in categories_list ))\n",
    "    return 'P-Value is ',result[1]\n",
    "anova('policy_annual_premium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding if a categorical variable is correlated with output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('p value :', 0.01803296321162173)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "def chi2_test(col_name):\n",
    "    contingency_table1 = pd.crosstab(insurance_df[col_name],insurance_df[\"fraud_reported\"])\n",
    "    p_val = chi2_contingency(contingency_table1)\n",
    "    return 'p value :',p_val[1]\n",
    "\n",
    "chi2_test('property_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'insured_hobbies'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chi2(col_name):\n",
    "    contingency_table = pd.crosstab(insurance_df[col_name],insurance_df[\"fraud_reported\"])\n",
    "    p_val = chi2_contingency(contingency_table)\n",
    "    if p_val[1] < 0.05:\n",
    "        return col_name\n",
    "chi2('insured_hobbies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns correlated to fraud_reported are: [None, None, None, None, None, None, 'insured_hobbies', None, None, 'incident_type', 'collision_type', 'incident_severity', 'authorities_contacted', 'incident_state', None, None, 'property_damage', None, None, None, 'fraud_reported']\n"
     ]
    }
   ],
   "source": [
    "corr_cols = [ ]\n",
    "for col in cat_cols:\n",
    "    corr_cols.append(chi2(col))\n",
    "print('columns correlated to fraud_reported are:',corr_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = insurance_df[\"fraud_reported\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df.drop(columns =\"fraud_reported\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>17-10-2014</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>27-06-2006</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>6/9/2000</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>25-05-1990</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>6/6/2014</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>941851</td>\n",
       "      <td>16-07-1991</td>\n",
       "      <td>OH</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1310.80</td>\n",
       "      <td>0</td>\n",
       "      <td>431289</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>87200</td>\n",
       "      <td>17440</td>\n",
       "      <td>8720</td>\n",
       "      <td>61040</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Accord</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>285</td>\n",
       "      <td>41</td>\n",
       "      <td>186934</td>\n",
       "      <td>5/1/2014</td>\n",
       "      <td>IL</td>\n",
       "      <td>100/300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1436.79</td>\n",
       "      <td>0</td>\n",
       "      <td>608177</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>108480</td>\n",
       "      <td>18080</td>\n",
       "      <td>18080</td>\n",
       "      <td>72320</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>130</td>\n",
       "      <td>34</td>\n",
       "      <td>918516</td>\n",
       "      <td>17-02-2003</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>500</td>\n",
       "      <td>1383.49</td>\n",
       "      <td>3000000</td>\n",
       "      <td>442797</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>67500</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500</td>\n",
       "      <td>52500</td>\n",
       "      <td>Suburu</td>\n",
       "      <td>Impreza</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>458</td>\n",
       "      <td>62</td>\n",
       "      <td>533940</td>\n",
       "      <td>18-11-2011</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1356.92</td>\n",
       "      <td>5000000</td>\n",
       "      <td>441714</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>46980</td>\n",
       "      <td>5220</td>\n",
       "      <td>5220</td>\n",
       "      <td>36540</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A5</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>456</td>\n",
       "      <td>60</td>\n",
       "      <td>556080</td>\n",
       "      <td>11/11/1996</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>766.19</td>\n",
       "      <td>0</td>\n",
       "      <td>612260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>5060</td>\n",
       "      <td>460</td>\n",
       "      <td>920</td>\n",
       "      <td>3680</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                   328   48         521585       17-10-2014           OH   \n",
       "1                   228   42         342868       27-06-2006           IN   \n",
       "2                   134   29         687698         6/9/2000           OH   \n",
       "3                   256   41         227811       25-05-1990           IL   \n",
       "4                   228   44         367455         6/6/2014           IL   \n",
       "..                  ...  ...            ...              ...          ...   \n",
       "995                   3   38         941851       16-07-1991           OH   \n",
       "996                 285   41         186934         5/1/2014           IL   \n",
       "997                 130   34         918516       17-02-2003           OH   \n",
       "998                 458   62         533940       18-11-2011           IL   \n",
       "999                 456   60         556080       11/11/1996           OH   \n",
       "\n",
       "    policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0      250/500               1000                1406.91               0   \n",
       "1      250/500               2000                1197.22         5000000   \n",
       "2      100/300               2000                1413.14         5000000   \n",
       "3      250/500               2000                1415.74         6000000   \n",
       "4     500/1000               1000                1583.91         6000000   \n",
       "..         ...                ...                    ...             ...   \n",
       "995   500/1000               1000                1310.80               0   \n",
       "996    100/300               1000                1436.79               0   \n",
       "997    250/500                500                1383.49         3000000   \n",
       "998   500/1000               2000                1356.92         5000000   \n",
       "999    250/500               1000                 766.19               0   \n",
       "\n",
       "     insured_zip  ... bodily_injuries witnesses police_report_available  \\\n",
       "0         466132  ...               1         2                     YES   \n",
       "1         468176  ...               0         0                       ?   \n",
       "2         430632  ...               2         3                      NO   \n",
       "3         608117  ...               1         2                      NO   \n",
       "4         610706  ...               0         1                      NO   \n",
       "..           ...  ...             ...       ...                     ...   \n",
       "995       431289  ...               0         1                       ?   \n",
       "996       608177  ...               2         3                       ?   \n",
       "997       442797  ...               2         3                     YES   \n",
       "998       441714  ...               0         1                     YES   \n",
       "999       612260  ...               0         3                       ?   \n",
       "\n",
       "    total_claim_amount injury_claim  property_claim  vehicle_claim  \\\n",
       "0                71610         6510           13020          52080   \n",
       "1                 5070          780             780           3510   \n",
       "2                34650         7700            3850          23100   \n",
       "3                63400         6340            6340          50720   \n",
       "4                 6500         1300             650           4550   \n",
       "..                 ...          ...             ...            ...   \n",
       "995              87200        17440            8720          61040   \n",
       "996             108480        18080           18080          72320   \n",
       "997              67500         7500            7500          52500   \n",
       "998              46980         5220            5220          36540   \n",
       "999               5060          460             920           3680   \n",
       "\n",
       "      auto_make auto_model auto_year  \n",
       "0          Saab        92x      2004  \n",
       "1      Mercedes       E400      2007  \n",
       "2         Dodge        RAM      2007  \n",
       "3     Chevrolet      Tahoe      2014  \n",
       "4        Accura        RSX      2009  \n",
       "..          ...        ...       ...  \n",
       "995       Honda     Accord      2006  \n",
       "996  Volkswagen     Passat      2015  \n",
       "997      Suburu    Impreza      1996  \n",
       "998        Audi         A5      1998  \n",
       "999    Mercedes       E400      2007  \n",
       "\n",
       "[1000 rows x 38 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns with morethan 50 % NA\n",
    "\n",
    "na_df=pd.DataFrame({'col_name':insurance_df.columns,'na_count':insurance_df.isnull().sum(),\n",
    "                   'na_pc':insurance_df.isnull().sum()/insurance_df.shape[0]*100})\n",
    "col_grt50_nas=na_df[na_df['na_pc']>50]['col_name'].values\n",
    "len(col_grt50_nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(insurance_df,y,test_size=0.2,random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filling missing values after train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'int64' or X_train[col].dtype == 'float64':\n",
    "        X_train[col].fillna(X_train[col].mean(),inplace= True)   # fill missing values of continous variables with mean\n",
    "        X_test[col].fillna(X_train[col].mean(),inplace= True)\n",
    "    if X_train[col].dtype == 'object':\n",
    "        X_train[col].fillna(X_train[col].mode(),inplace= True)   # fill missing values of categorical variables with mode\n",
    "        X_test[col].fillna(X_train[col].mode(),inplace= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling continous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.705671</td>\n",
       "      <td>0.645901</td>\n",
       "      <td>-0.891007</td>\n",
       "      <td>-0.224959</td>\n",
       "      <td>-0.104028</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.836892</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>-0.977436</td>\n",
       "      <td>1.060777</td>\n",
       "      <td>-0.822213</td>\n",
       "      <td>-1.223219</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>0.032611</td>\n",
       "      <td>-0.440172</td>\n",
       "      <td>-0.425708</td>\n",
       "      <td>0.268847</td>\n",
       "      <td>0.171297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-0.092012</td>\n",
       "      <td>0.213951</td>\n",
       "      <td>-1.222032</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>-0.213343</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>1.574374</td>\n",
       "      <td>0.973770</td>\n",
       "      <td>-0.860647</td>\n",
       "      <td>0.773983</td>\n",
       "      <td>1.144216</td>\n",
       "      <td>-1.223219</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>1.658699</td>\n",
       "      <td>1.292629</td>\n",
       "      <td>2.750265</td>\n",
       "      <td>1.271267</td>\n",
       "      <td>-0.980281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>-0.675264</td>\n",
       "      <td>-1.189890</td>\n",
       "      <td>0.184679</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>1.027383</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.388008</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>-1.233570</td>\n",
       "      <td>2.127430</td>\n",
       "      <td>-1.223219</td>\n",
       "      <td>-0.434182</td>\n",
       "      <td>0.573353</td>\n",
       "      <td>0.792783</td>\n",
       "      <td>0.813696</td>\n",
       "      <td>0.385195</td>\n",
       "      <td>0.993853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-0.803923</td>\n",
       "      <td>-1.297877</td>\n",
       "      <td>-0.140213</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>0.437175</td>\n",
       "      <td>1.226979</td>\n",
       "      <td>1.452104</td>\n",
       "      <td>0.924147</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>-0.822213</td>\n",
       "      <td>1.229350</td>\n",
       "      <td>1.384381</td>\n",
       "      <td>1.468281</td>\n",
       "      <td>1.884114</td>\n",
       "      <td>1.910736</td>\n",
       "      <td>1.068736</td>\n",
       "      <td>0.664831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>-1.095549</td>\n",
       "      <td>-1.405865</td>\n",
       "      <td>-0.754597</td>\n",
       "      <td>1.411105</td>\n",
       "      <td>-1.913204</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>1.673511</td>\n",
       "      <td>0.874525</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>1.144216</td>\n",
       "      <td>1.229350</td>\n",
       "      <td>-1.343463</td>\n",
       "      <td>0.622792</td>\n",
       "      <td>1.055202</td>\n",
       "      <td>-0.237285</td>\n",
       "      <td>0.656672</td>\n",
       "      <td>0.664831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.336850</td>\n",
       "      <td>0.105963</td>\n",
       "      <td>0.176150</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>0.351895</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.853928</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>-1.376966</td>\n",
       "      <td>-0.822213</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>1.384381</td>\n",
       "      <td>-1.815954</td>\n",
       "      <td>-1.423204</td>\n",
       "      <td>-1.413881</td>\n",
       "      <td>-1.800628</td>\n",
       "      <td>1.487387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-0.349329</td>\n",
       "      <td>-0.110012</td>\n",
       "      <td>-0.904249</td>\n",
       "      <td>1.411105</td>\n",
       "      <td>0.054860</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.458934</td>\n",
       "      <td>0.683123</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>-1.090173</td>\n",
       "      <td>-0.822213</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>1.384381</td>\n",
       "      <td>1.430815</td>\n",
       "      <td>2.188188</td>\n",
       "      <td>0.332171</td>\n",
       "      <td>1.343984</td>\n",
       "      <td>1.651898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>-1.481525</td>\n",
       "      <td>-0.110012</td>\n",
       "      <td>-0.757052</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>-1.014655</td>\n",
       "      <td>2.082389</td>\n",
       "      <td>-0.313068</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>0.487190</td>\n",
       "      <td>1.144216</td>\n",
       "      <td>1.229350</td>\n",
       "      <td>-0.434182</td>\n",
       "      <td>0.693089</td>\n",
       "      <td>1.392599</td>\n",
       "      <td>-0.067704</td>\n",
       "      <td>0.623815</td>\n",
       "      <td>-1.309303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1.220305</td>\n",
       "      <td>1.293828</td>\n",
       "      <td>-0.809392</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>0.913066</td>\n",
       "      <td>3.365504</td>\n",
       "      <td>-0.953274</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>0.526673</td>\n",
       "      <td>0.487190</td>\n",
       "      <td>-0.822213</td>\n",
       "      <td>-1.223219</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>1.954562</td>\n",
       "      <td>0.236703</td>\n",
       "      <td>2.061475</td>\n",
       "      <td>2.134177</td>\n",
       "      <td>-1.309303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.838232</td>\n",
       "      <td>-0.865926</td>\n",
       "      <td>0.647475</td>\n",
       "      <td>1.411105</td>\n",
       "      <td>-0.966017</td>\n",
       "      <td>1.654684</td>\n",
       "      <td>-0.432317</td>\n",
       "      <td>-0.178185</td>\n",
       "      <td>-1.971918</td>\n",
       "      <td>1.347570</td>\n",
       "      <td>1.144216</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.475099</td>\n",
       "      <td>1.574884</td>\n",
       "      <td>1.442583</td>\n",
       "      <td>2.976373</td>\n",
       "      <td>1.057424</td>\n",
       "      <td>-0.651259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer       age  policy_number  policy_deductable  \\\n",
       "632            0.705671  0.645901      -0.891007          -0.224959   \n",
       "687           -0.092012  0.213951      -1.222032          -1.042991   \n",
       "833           -0.675264 -1.189890       0.184679          -1.042991   \n",
       "182           -0.803923 -1.297877      -0.140213          -1.042991   \n",
       "831           -1.095549 -1.405865      -0.754597           1.411105   \n",
       "..                  ...       ...            ...                ...   \n",
       "258            0.336850  0.105963       0.176150          -1.042991   \n",
       "118           -0.349329 -0.110012      -0.904249           1.411105   \n",
       "279           -1.481525 -0.110012      -0.757052          -1.042991   \n",
       "458            1.220305  1.293828      -0.809392          -1.042991   \n",
       "301           -0.838232 -0.865926       0.647475           1.411105   \n",
       "\n",
       "     policy_annual_premium  umbrella_limit  insured_zip  capital-gains  \\\n",
       "632              -0.104028       -0.483841    -0.836892      -0.887081   \n",
       "687              -0.213343       -0.483841     1.574374       0.973770   \n",
       "833               1.027383       -0.483841    -0.388008      -0.887081   \n",
       "182               0.437175        1.226979     1.452104       0.924147   \n",
       "831              -1.913204       -0.483841     1.673511       0.874525   \n",
       "..                     ...             ...          ...            ...   \n",
       "258               0.351895       -0.483841    -0.853928      -0.887081   \n",
       "118               0.054860       -0.483841    -0.458934       0.683123   \n",
       "279              -1.014655        2.082389    -0.313068      -0.887081   \n",
       "458               0.913066        3.365504    -0.953274      -0.887081   \n",
       "301              -0.966017        1.654684    -0.432317      -0.178185   \n",
       "\n",
       "     capital-loss  incident_hour_of_the_day  number_of_vehicles_involved  \\\n",
       "632     -0.977436                  1.060777                    -0.822213   \n",
       "687     -0.860647                  0.773983                     1.144216   \n",
       "833      0.954901                 -1.233570                     2.127430   \n",
       "182      0.954901                  0.057000                    -0.822213   \n",
       "831      0.954901                  0.057000                     1.144216   \n",
       "..            ...                       ...                          ...   \n",
       "258      0.954901                 -1.376966                    -0.822213   \n",
       "118      0.954901                 -1.090173                    -0.822213   \n",
       "279      0.954901                  0.487190                     1.144216   \n",
       "458      0.526673                  0.487190                    -0.822213   \n",
       "301     -1.971918                  1.347570                     1.144216   \n",
       "\n",
       "     bodily_injuries  witnesses  total_claim_amount  injury_claim  \\\n",
       "632        -1.223219   0.475099            0.032611     -0.440172   \n",
       "687        -1.223219   0.475099            1.658699      1.292629   \n",
       "833        -1.223219  -0.434182            0.573353      0.792783   \n",
       "182         1.229350   1.384381            1.468281      1.884114   \n",
       "831         1.229350  -1.343463            0.622792      1.055202   \n",
       "..               ...        ...                 ...           ...   \n",
       "258         0.003066   1.384381           -1.815954     -1.423204   \n",
       "118         0.003066   1.384381            1.430815      2.188188   \n",
       "279         1.229350  -0.434182            0.693089      1.392599   \n",
       "458        -1.223219   0.475099            1.954562      0.236703   \n",
       "301         0.003066   0.475099            1.574884      1.442583   \n",
       "\n",
       "     property_claim  vehicle_claim  auto_year  \n",
       "632       -0.425708       0.268847   0.171297  \n",
       "687        2.750265       1.271267  -0.980281  \n",
       "833        0.813696       0.385195   0.993853  \n",
       "182        1.910736       1.068736   0.664831  \n",
       "831       -0.237285       0.656672   0.664831  \n",
       "..              ...            ...        ...  \n",
       "258       -1.413881      -1.800628   1.487387  \n",
       "118        0.332171       1.343984   1.651898  \n",
       "279       -0.067704       0.623815  -1.309303  \n",
       "458        2.061475       2.134177  -1.309303  \n",
       "301        2.976373       1.057424  -0.651259  \n",
       "\n",
       "[200 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "for col in con_cols:\n",
    "    X_train[col] = std_scaler.fit_transform(np.array(X_train[col]).reshape(-1,1))\n",
    "    X_test[col] = std_scaler.transform(np.array(X_test[col]).reshape(-1,1))\n",
    "X_train[con_cols] \n",
    "X_test[con_cols] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['policy_bind_date_14-12-1991', 'policy_bind_date_19-09-1995',\n",
       "       'policy_bind_date_25-09-2001', 'policy_bind_date_25-12-2013',\n",
       "       'policy_bind_date_28-12-1991', 'policy_bind_date_3/2/1997',\n",
       "       'policy_bind_date_5/1/1992', 'policy_bind_date_6/5/2007',\n",
       "       'policy_bind_date_8/11/2009', 'policy_bind_date_9/3/2003',\n",
       "       ...\n",
       "       'auto_model_Pathfinder', 'auto_model_RAM', 'auto_model_RSX',\n",
       "       'auto_model_Silverado', 'auto_model_TL', 'auto_model_Tahoe',\n",
       "       'auto_model_Ultima', 'auto_model_Wrangler', 'auto_model_X5',\n",
       "       'auto_model_X6'],\n",
       "      dtype='object', length=214)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train =  pd.get_dummies(X_train[[col for col in X_train.columns if X_train[col].dtype=='object']])\n",
    "one_hot_test = pd.get_dummies(X_test[[col for col in X_test.columns if X_train[col].dtype=='object']])\n",
    "one_hot_train_final,one_hot_test_final = one_hot_train.align(one_hot_test,join='inner',axis=1) # includes only common columns excludes those which are in train but not in test\n",
    "one_hot_train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_model_Pathfinder</th>\n",
       "      <th>auto_model_RAM</th>\n",
       "      <th>auto_model_RSX</th>\n",
       "      <th>auto_model_Silverado</th>\n",
       "      <th>auto_model_TL</th>\n",
       "      <th>auto_model_Tahoe</th>\n",
       "      <th>auto_model_Ultima</th>\n",
       "      <th>auto_model_Wrangler</th>\n",
       "      <th>auto_model_X5</th>\n",
       "      <th>auto_model_X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>-1.464370</td>\n",
       "      <td>-1.621840</td>\n",
       "      <td>-0.264371</td>\n",
       "      <td>1.411105</td>\n",
       "      <td>1.196682</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.908056</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>-0.025424</td>\n",
       "      <td>1.204173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>-0.083435</td>\n",
       "      <td>-0.110012</td>\n",
       "      <td>-1.221185</td>\n",
       "      <td>1.411105</td>\n",
       "      <td>0.157220</td>\n",
       "      <td>2.082389</td>\n",
       "      <td>-0.324481</td>\n",
       "      <td>0.459821</td>\n",
       "      <td>-0.825256</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.126321</td>\n",
       "      <td>0.105963</td>\n",
       "      <td>-0.625239</td>\n",
       "      <td>1.411105</td>\n",
       "      <td>-1.183669</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>1.535701</td>\n",
       "      <td>0.420832</td>\n",
       "      <td>-0.945585</td>\n",
       "      <td>-0.229793</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>-0.315020</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>-1.301626</td>\n",
       "      <td>-0.224959</td>\n",
       "      <td>0.542179</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.299613</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>-0.552747</td>\n",
       "      <td>1.634363</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0.251077</td>\n",
       "      <td>0.429926</td>\n",
       "      <td>1.628860</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.730958</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>-0.772170</td>\n",
       "      <td>-1.090173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0.088110</td>\n",
       "      <td>-0.433976</td>\n",
       "      <td>-0.861556</td>\n",
       "      <td>-0.224959</td>\n",
       "      <td>-0.532217</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>1.476818</td>\n",
       "      <td>0.530710</td>\n",
       "      <td>-0.581059</td>\n",
       "      <td>-0.803380</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.414045</td>\n",
       "      <td>0.213951</td>\n",
       "      <td>-1.131371</td>\n",
       "      <td>1.411105</td>\n",
       "      <td>0.229689</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.407044</td>\n",
       "      <td>1.994580</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>-0.229793</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>-1.713110</td>\n",
       "      <td>-1.945804</td>\n",
       "      <td>0.110477</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>-1.386194</td>\n",
       "      <td>1.654684</td>\n",
       "      <td>1.563143</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>1.634363</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1.366118</td>\n",
       "      <td>1.293828</td>\n",
       "      <td>-0.642686</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.302858</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>0.630587</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>-1.421484</td>\n",
       "      <td>-1.837816</td>\n",
       "      <td>0.554088</td>\n",
       "      <td>-1.042991</td>\n",
       "      <td>-0.337785</td>\n",
       "      <td>-0.483841</td>\n",
       "      <td>-0.970016</td>\n",
       "      <td>-0.887081</td>\n",
       "      <td>0.954901</td>\n",
       "      <td>0.343793</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer       age  policy_number  policy_deductable  \\\n",
       "799           -1.464370 -1.621840      -0.264371           1.411105   \n",
       "471           -0.083435 -0.110012      -1.221185           1.411105   \n",
       "242           -0.126321  0.105963      -0.625239           1.411105   \n",
       "704           -0.315020 -0.002025      -1.301626          -0.224959   \n",
       "839            0.251077  0.429926       1.628860          -1.042991   \n",
       "..                  ...       ...            ...                ...   \n",
       "892            0.088110 -0.433976      -0.861556          -0.224959   \n",
       "310            0.414045  0.213951      -1.131371           1.411105   \n",
       "901           -1.713110 -1.945804       0.110477          -1.042991   \n",
       "555            1.366118  1.293828      -0.642686          -1.042991   \n",
       "727           -1.421484 -1.837816       0.554088          -1.042991   \n",
       "\n",
       "     policy_annual_premium  umbrella_limit  insured_zip  capital-gains  \\\n",
       "799               1.196682       -0.483841    -0.908056      -0.887081   \n",
       "471               0.157220        2.082389    -0.324481       0.459821   \n",
       "242              -1.183669       -0.483841     1.535701       0.420832   \n",
       "704               0.542179       -0.483841    -0.299613      -0.887081   \n",
       "839               0.003131       -0.483841    -0.730958      -0.887081   \n",
       "..                     ...             ...          ...            ...   \n",
       "892              -0.532217       -0.483841     1.476818       0.530710   \n",
       "310               0.229689       -0.483841    -0.407044       1.994580   \n",
       "901              -1.386194        1.654684     1.563143      -0.887081   \n",
       "555               0.049126       -0.483841    -0.302858      -0.887081   \n",
       "727              -0.337785       -0.483841    -0.970016      -0.887081   \n",
       "\n",
       "     capital-loss  incident_hour_of_the_day  ...  auto_model_Pathfinder  \\\n",
       "799     -0.025424                  1.204173  ...                      0   \n",
       "471     -0.825256                  0.057000  ...                      0   \n",
       "242     -0.945585                 -0.229793  ...                      0   \n",
       "704     -0.552747                  1.634363  ...                      0   \n",
       "839     -0.772170                 -1.090173  ...                      0   \n",
       "..            ...                       ...  ...                    ...   \n",
       "892     -0.581059                 -0.803380  ...                      0   \n",
       "310      0.954901                 -0.229793  ...                      0   \n",
       "901      0.954901                  1.634363  ...                      1   \n",
       "555      0.954901                  0.630587  ...                      0   \n",
       "727      0.954901                  0.343793  ...                      0   \n",
       "\n",
       "     auto_model_RAM  auto_model_RSX  auto_model_Silverado  auto_model_TL  \\\n",
       "799               0               0                     0              0   \n",
       "471               0               0                     0              0   \n",
       "242               0               0                     0              0   \n",
       "704               0               0                     0              0   \n",
       "839               0               0                     0              0   \n",
       "..              ...             ...                   ...            ...   \n",
       "892               0               0                     0              0   \n",
       "310               0               0                     0              0   \n",
       "901               0               0                     0              0   \n",
       "555               0               0                     0              0   \n",
       "727               0               0                     0              0   \n",
       "\n",
       "     auto_model_Tahoe  auto_model_Ultima  auto_model_Wrangler  auto_model_X5  \\\n",
       "799                 0                  0                    0              0   \n",
       "471                 0                  0                    0              0   \n",
       "242                 0                  1                    0              0   \n",
       "704                 0                  0                    0              0   \n",
       "839                 0                  0                    0              0   \n",
       "..                ...                ...                  ...            ...   \n",
       "892                 0                  0                    1              0   \n",
       "310                 0                  0                    0              0   \n",
       "901                 0                  0                    0              0   \n",
       "555                 0                  0                    0              0   \n",
       "727                 0                  0                    0              0   \n",
       "\n",
       "     auto_model_X6  \n",
       "799              0  \n",
       "471              0  \n",
       "242              0  \n",
       "704              0  \n",
       "839              0  \n",
       "..             ...  \n",
       "892              0  \n",
       "310              0  \n",
       "901              0  \n",
       "555              0  \n",
       "727              0  \n",
       "\n",
       "[800 rows x 232 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatinates scaled and one hot encoded data\n",
    "\n",
    "X_train_final = pd.concat([X_train[con_cols],one_hot_train_final],axis = 1)\n",
    "\n",
    "X_test_final = pd.concat([X_test[con_cols],one_hot_test_final],axis = 1)\n",
    "X_train_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing Y/N with 1/0 (since could not convert string to float: 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace({'Y':1,'N':0},inplace = True) \n",
    "y_test.replace({'Y':1,'N':0},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799    0\n",
       "471    0\n",
       "242    0\n",
       "704    1\n",
       "839    0\n",
       "      ..\n",
       "892    0\n",
       "310    1\n",
       "901    0\n",
       "555    1\n",
       "727    1\n",
       "Name: fraud_reported, Length: 800, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculating VIF (multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>months_as_customer</td>\n",
       "      <td>8.760797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>8.665812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>policy_number</td>\n",
       "      <td>1.338628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>policy_deductable</td>\n",
       "      <td>1.271202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>policy_annual_premium</td>\n",
       "      <td>1.341764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>auto_model_Tahoe</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>auto_model_Ultima</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>auto_model_Wrangler</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>auto_model_X5</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>auto_model_X6</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature       VIF\n",
       "0       months_as_customer  8.760797\n",
       "1                      age  8.665812\n",
       "2            policy_number  1.338628\n",
       "3        policy_deductable  1.271202\n",
       "4    policy_annual_premium  1.341764\n",
       "..                     ...       ...\n",
       "227       auto_model_Tahoe       inf\n",
       "228      auto_model_Ultima       inf\n",
       "229    auto_model_Wrangler       inf\n",
       "230          auto_model_X5       inf\n",
       "231          auto_model_X6       inf\n",
       "\n",
       "[232 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_train_final.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_final.values, i)\n",
    "                   for i in range(len(X_train_final.columns))]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x145d1040a90>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca=PCA()\n",
    "X_train_pca_df=pd.DataFrame(pca.fit_transform(X_train_final))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1=PCA(n_components=50)\n",
    "\n",
    "X_train_pca_df=pd.DataFrame(pca_1.fit_transform(X_train_final),columns=list(range(0,50)))\n",
    "\n",
    "X_test_pca_df=pd.DataFrame(pca_1.transform(X_test_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor_PCA</th>\n",
       "      <th>Column Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor_PCA  Column Name\n",
       "0              1.0            0\n",
       "1              1.0            1\n",
       "2              1.0            2\n",
       "3              1.0            3\n",
       "4              1.0            4\n",
       "5              1.0            5\n",
       "6              1.0            6\n",
       "7              1.0            7\n",
       "8              1.0            8\n",
       "9              1.0            9\n",
       "10             1.0           10\n",
       "11             1.0           11\n",
       "12             1.0           12\n",
       "13             1.0           13\n",
       "14             1.0           14\n",
       "15             1.0           15\n",
       "16             1.0           16\n",
       "17             1.0           17\n",
       "18             1.0           18\n",
       "19             1.0           19\n",
       "20             1.0           20\n",
       "21             1.0           21\n",
       "22             1.0           22\n",
       "23             1.0           23\n",
       "24             1.0           24\n",
       "25             1.0           25\n",
       "26             1.0           26\n",
       "27             1.0           27\n",
       "28             1.0           28\n",
       "29             1.0           29\n",
       "30             1.0           30\n",
       "31             1.0           31\n",
       "32             1.0           32\n",
       "33             1.0           33\n",
       "34             1.0           34\n",
       "35             1.0           35\n",
       "36             1.0           36\n",
       "37             1.0           37\n",
       "38             1.0           38\n",
       "39             1.0           39\n",
       "40             1.0           40\n",
       "41             1.0           41\n",
       "42             1.0           42\n",
       "43             1.0           43\n",
       "44             1.0           44\n",
       "45             1.0           45\n",
       "46             1.0           46\n",
       "47             1.0           47\n",
       "48             1.0           48\n",
       "49             1.0           49"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proof that PCA results in Zero or No Multicollinearity\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_pca = pd.DataFrame()\n",
    "vif_pca[\"VIF Factor_PCA\"] = [variance_inflation_factor(X_train_pca_df.values, i) for i in range(X_train_pca_df.shape[1])]\n",
    "\n",
    "vif_pca['Column Name']=X_train_pca_df.columns\n",
    "\n",
    "vif_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic Regression-PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.8375\n",
      "test score = 0.735\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_pca_df,y_train)   #train the model on training data\n",
    "print('train score =',logreg.score(X_train_pca_df,y_train))\n",
    "print('test score =',logreg.score(X_test_pca_df,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = logreg.predict(X_test_pca_df)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[131,  18],\n",
       "       [ 35,  16]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score 0.47058823529411764\n",
      "recall score 0.3137254901960784\n",
      "test f1_score : 0.3764705882352941\n"
     ]
    }
   ],
   "source": [
    "#test scores\n",
    "\n",
    "print('precision score',precision_score(y_test,test_predictions))\n",
    "print('recall score',recall_score(y_test,test_predictions))\n",
    "print('test f1_score :',f1_score(y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.9175\n",
      "test score = 0.805\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_final,y_train)   #train the model on training data\n",
    "print('train score =',logreg.score(X_train_final,y_train))\n",
    "print('test score =',logreg.score(X_test_final,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = logreg.predict(X_test_final)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = logreg.predict(X_train_final)\n",
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.88259838e-01, 1.17401616e-02],\n",
       "       [6.11587597e-01, 3.88412403e-01],\n",
       "       [7.95206312e-01, 2.04793688e-01],\n",
       "       [9.67963569e-01, 3.20364308e-02],\n",
       "       [1.06582074e-01, 8.93417926e-01],\n",
       "       [6.06563422e-01, 3.93436578e-01],\n",
       "       [8.46316459e-01, 1.53683541e-01],\n",
       "       [8.56672964e-01, 1.43327036e-01],\n",
       "       [7.52895789e-01, 2.47104211e-01],\n",
       "       [1.40932453e-01, 8.59067547e-01],\n",
       "       [5.23324032e-02, 9.47667597e-01],\n",
       "       [9.96065789e-01, 3.93421068e-03],\n",
       "       [9.69285665e-01, 3.07143355e-02],\n",
       "       [9.73523051e-01, 2.64769488e-02],\n",
       "       [8.36473622e-01, 1.63526378e-01],\n",
       "       [8.72576248e-02, 9.12742375e-01],\n",
       "       [9.13669871e-01, 8.63301291e-02],\n",
       "       [3.04022094e-01, 6.95977906e-01],\n",
       "       [8.59264332e-01, 1.40735668e-01],\n",
       "       [9.83693418e-01, 1.63065824e-02],\n",
       "       [8.70921007e-01, 1.29078993e-01],\n",
       "       [9.52566864e-01, 4.74331364e-02],\n",
       "       [9.53945240e-01, 4.60547599e-02],\n",
       "       [3.47453107e-01, 6.52546893e-01],\n",
       "       [5.71507183e-01, 4.28492817e-01],\n",
       "       [9.68323377e-01, 3.16766232e-02],\n",
       "       [9.64604881e-01, 3.53951189e-02],\n",
       "       [9.89210733e-01, 1.07892667e-02],\n",
       "       [7.36105359e-02, 9.26389464e-01],\n",
       "       [9.65690247e-01, 3.43097526e-02],\n",
       "       [1.28664813e-01, 8.71335187e-01],\n",
       "       [9.45824756e-01, 5.41752436e-02],\n",
       "       [9.77840316e-01, 2.21596842e-02],\n",
       "       [8.76678065e-01, 1.23321935e-01],\n",
       "       [8.72938693e-01, 1.27061307e-01],\n",
       "       [6.37462219e-01, 3.62537781e-01],\n",
       "       [9.57910597e-01, 4.20894035e-02],\n",
       "       [3.19447356e-01, 6.80552644e-01],\n",
       "       [9.86788567e-01, 1.32114335e-02],\n",
       "       [3.32327388e-01, 6.67672612e-01],\n",
       "       [5.90338879e-01, 4.09661121e-01],\n",
       "       [7.55825580e-01, 2.44174420e-01],\n",
       "       [9.87088256e-01, 1.29117436e-02],\n",
       "       [9.85099973e-01, 1.49000275e-02],\n",
       "       [8.57120663e-01, 1.42879337e-01],\n",
       "       [2.66797885e-01, 7.33202115e-01],\n",
       "       [9.61168938e-01, 3.88310615e-02],\n",
       "       [9.86410127e-01, 1.35898728e-02],\n",
       "       [8.86815841e-01, 1.13184159e-01],\n",
       "       [9.66995385e-01, 3.30046152e-02],\n",
       "       [9.87988825e-01, 1.20111746e-02],\n",
       "       [4.35776903e-01, 5.64223097e-01],\n",
       "       [9.43893088e-01, 5.61069117e-02],\n",
       "       [9.10975498e-01, 8.90245017e-02],\n",
       "       [9.98539683e-01, 1.46031746e-03],\n",
       "       [9.93123676e-01, 6.87632355e-03],\n",
       "       [4.72093783e-01, 5.27906217e-01],\n",
       "       [7.56936484e-01, 2.43063516e-01],\n",
       "       [9.30491957e-01, 6.95080426e-02],\n",
       "       [4.43764677e-01, 5.56235323e-01],\n",
       "       [9.93733219e-01, 6.26678052e-03],\n",
       "       [1.40391291e-01, 8.59608709e-01],\n",
       "       [9.94337898e-01, 5.66210182e-03],\n",
       "       [4.14310853e-01, 5.85689147e-01],\n",
       "       [3.40660970e-01, 6.59339030e-01],\n",
       "       [6.88362678e-01, 3.11637322e-01],\n",
       "       [9.03865036e-01, 9.61349643e-02],\n",
       "       [9.81796545e-01, 1.82034550e-02],\n",
       "       [9.95579060e-01, 4.42093990e-03],\n",
       "       [3.95665247e-01, 6.04334753e-01],\n",
       "       [9.60395304e-01, 3.96046964e-02],\n",
       "       [8.49710349e-01, 1.50289651e-01],\n",
       "       [9.79607189e-01, 2.03928113e-02],\n",
       "       [9.65586623e-01, 3.44133766e-02],\n",
       "       [7.51887662e-01, 2.48112338e-01],\n",
       "       [9.09383272e-01, 9.06167281e-02],\n",
       "       [9.14545155e-01, 8.54548452e-02],\n",
       "       [4.38836740e-01, 5.61163260e-01],\n",
       "       [8.99738123e-02, 9.10026188e-01],\n",
       "       [5.34741119e-01, 4.65258881e-01],\n",
       "       [3.10533451e-01, 6.89466549e-01],\n",
       "       [9.95035350e-01, 4.96464992e-03],\n",
       "       [1.40914849e-01, 8.59085151e-01],\n",
       "       [9.99265447e-01, 7.34553337e-04],\n",
       "       [9.65457102e-01, 3.45428979e-02],\n",
       "       [6.05801434e-01, 3.94198566e-01],\n",
       "       [9.78054395e-01, 2.19456048e-02],\n",
       "       [4.72088402e-01, 5.27911598e-01],\n",
       "       [9.70525951e-01, 2.94740486e-02],\n",
       "       [4.90161286e-01, 5.09838714e-01],\n",
       "       [9.85510716e-01, 1.44892843e-02],\n",
       "       [5.31424343e-02, 9.46857566e-01],\n",
       "       [8.76634215e-01, 1.23365785e-01],\n",
       "       [9.71491870e-01, 2.85081302e-02],\n",
       "       [7.07779321e-01, 2.92220679e-01],\n",
       "       [5.86483427e-01, 4.13516573e-01],\n",
       "       [9.75770901e-01, 2.42290992e-02],\n",
       "       [9.72117482e-01, 2.78825183e-02],\n",
       "       [9.68558375e-01, 3.14416254e-02],\n",
       "       [4.17904299e-01, 5.82095701e-01],\n",
       "       [3.48435021e-01, 6.51564979e-01],\n",
       "       [9.32429902e-01, 6.75700976e-02],\n",
       "       [1.52490337e-01, 8.47509663e-01],\n",
       "       [8.16770634e-01, 1.83229366e-01],\n",
       "       [7.40747684e-01, 2.59252316e-01],\n",
       "       [8.25191871e-01, 1.74808129e-01],\n",
       "       [9.33127965e-01, 6.68720349e-02],\n",
       "       [6.92387462e-01, 3.07612538e-01],\n",
       "       [9.91222977e-01, 8.77702289e-03],\n",
       "       [6.07788180e-01, 3.92211820e-01],\n",
       "       [9.44917639e-01, 5.50823610e-02],\n",
       "       [9.48116892e-01, 5.18831083e-02],\n",
       "       [5.20288962e-01, 4.79711038e-01],\n",
       "       [8.50931309e-01, 1.49068691e-01],\n",
       "       [9.54824989e-01, 4.51750113e-02],\n",
       "       [9.91343440e-01, 8.65655954e-03],\n",
       "       [9.57832306e-01, 4.21676938e-02],\n",
       "       [9.59824968e-01, 4.01750325e-02],\n",
       "       [7.45475211e-01, 2.54524789e-01],\n",
       "       [9.93336547e-01, 6.66345347e-03],\n",
       "       [9.98352184e-01, 1.64781615e-03],\n",
       "       [8.92367759e-01, 1.07632241e-01],\n",
       "       [3.24858510e-01, 6.75141490e-01],\n",
       "       [5.00442542e-01, 4.99557458e-01],\n",
       "       [9.93477859e-01, 6.52214066e-03],\n",
       "       [9.84245343e-01, 1.57546569e-02],\n",
       "       [9.73517567e-01, 2.64824329e-02],\n",
       "       [9.84532758e-01, 1.54672422e-02],\n",
       "       [9.23537192e-01, 7.64628079e-02],\n",
       "       [9.18812711e-01, 8.11872887e-02],\n",
       "       [8.97202856e-01, 1.02797144e-01],\n",
       "       [9.84778968e-01, 1.52210318e-02],\n",
       "       [2.50831283e-01, 7.49168717e-01],\n",
       "       [9.88215548e-01, 1.17844519e-02],\n",
       "       [9.02968048e-01, 9.70319523e-02],\n",
       "       [1.70958224e-01, 8.29041776e-01],\n",
       "       [4.87955190e-01, 5.12044810e-01],\n",
       "       [9.67012540e-01, 3.29874597e-02],\n",
       "       [9.10994108e-01, 8.90058917e-02],\n",
       "       [1.37504279e-01, 8.62495721e-01],\n",
       "       [9.93915363e-01, 6.08463704e-03],\n",
       "       [9.21574209e-01, 7.84257906e-02],\n",
       "       [3.92305070e-01, 6.07694930e-01],\n",
       "       [9.39453966e-01, 6.05460343e-02],\n",
       "       [9.10073112e-01, 8.99268883e-02],\n",
       "       [8.71457861e-01, 1.28542139e-01],\n",
       "       [9.66158664e-01, 3.38413355e-02],\n",
       "       [1.13336345e-01, 8.86663655e-01],\n",
       "       [9.94944097e-01, 5.05590294e-03],\n",
       "       [9.80142848e-01, 1.98571520e-02],\n",
       "       [6.70948947e-01, 3.29051053e-01],\n",
       "       [4.53365079e-01, 5.46634921e-01],\n",
       "       [4.55800205e-02, 9.54419980e-01],\n",
       "       [9.54097234e-01, 4.59027664e-02],\n",
       "       [9.46193043e-01, 5.38069571e-02],\n",
       "       [7.25490323e-02, 9.27450968e-01],\n",
       "       [9.82145624e-01, 1.78543762e-02],\n",
       "       [1.19027284e-01, 8.80972716e-01],\n",
       "       [5.92381694e-01, 4.07618306e-01],\n",
       "       [9.80337894e-01, 1.96621058e-02],\n",
       "       [9.64801385e-01, 3.51986153e-02],\n",
       "       [9.87867227e-01, 1.21327731e-02],\n",
       "       [8.12704371e-01, 1.87295629e-01],\n",
       "       [9.57720365e-01, 4.22796354e-02],\n",
       "       [9.46385079e-01, 5.36149213e-02],\n",
       "       [9.34424455e-01, 6.55755445e-02],\n",
       "       [1.61772159e-01, 8.38227841e-01],\n",
       "       [9.80775671e-01, 1.92243290e-02],\n",
       "       [9.32553071e-01, 6.74469291e-02],\n",
       "       [4.51702720e-01, 5.48297280e-01],\n",
       "       [8.52209848e-01, 1.47790152e-01],\n",
       "       [9.13054984e-01, 8.69450162e-02],\n",
       "       [2.32568032e-01, 7.67431968e-01],\n",
       "       [9.45703419e-01, 5.42965813e-02],\n",
       "       [3.99048448e-01, 6.00951552e-01],\n",
       "       [9.88432185e-01, 1.15678146e-02],\n",
       "       [6.58204278e-01, 3.41795722e-01],\n",
       "       [6.69394684e-01, 3.30605316e-01],\n",
       "       [9.15634763e-01, 8.43652373e-02],\n",
       "       [8.46822959e-01, 1.53177041e-01],\n",
       "       [6.58544644e-03, 9.93414554e-01],\n",
       "       [9.16911771e-01, 8.30882291e-02],\n",
       "       [9.75115547e-01, 2.48844531e-02],\n",
       "       [9.85331810e-01, 1.46681901e-02],\n",
       "       [9.87622198e-01, 1.23778018e-02],\n",
       "       [8.19382509e-01, 1.80617491e-01],\n",
       "       [2.13529851e-01, 7.86470149e-01],\n",
       "       [5.28738689e-01, 4.71261311e-01],\n",
       "       [9.40117449e-01, 5.98825507e-02],\n",
       "       [1.53503734e-02, 9.84649627e-01],\n",
       "       [9.86364090e-01, 1.36359103e-02],\n",
       "       [9.51741489e-01, 4.82585113e-02],\n",
       "       [9.48092397e-01, 5.19076033e-02],\n",
       "       [9.86968264e-01, 1.30317361e-02],\n",
       "       [9.62888206e-01, 3.71117935e-02],\n",
       "       [9.80024603e-01, 1.99753974e-02],\n",
       "       [9.84211454e-01, 1.57885464e-02],\n",
       "       [9.70571570e-01, 2.94284296e-02],\n",
       "       [9.37610732e-01, 6.23892684e-02],\n",
       "       [9.61206981e-01, 3.87930193e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability = logreg.predict_proba(X_test_final) \n",
    "pos_probability = logreg.predict_proba(X_test_final)[::,1]\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,  17],\n",
       "       [ 22,  29]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actuals</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actuals  predictions\n",
       "632        0            0\n",
       "687        0            0\n",
       "833        0            0\n",
       "182        0            0\n",
       "831        1            1\n",
       "..       ...          ...\n",
       "258        0            0\n",
       "118        0            0\n",
       "279        0            0\n",
       "458        0            0\n",
       "301        0            0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparision_df = pd.DataFrame({'Actuals':y_test,'predictions':test_predictions})\n",
    "comparision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpr,tpr,thresholds = roc_curve(y_test,pos_probability,pos_label='Y')\n",
    "fpr,tpr,thresholds = roc_curve(y_test,pos_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score 0.6304347826086957\n",
      "recall score 0.5686274509803921\n",
      "test f1_score : 0.5979381443298969\n"
     ]
    }
   ],
   "source": [
    "#test scores\n",
    "#print('precision score',precision_score(y_test,test_predictions,pos_label='Y'))\n",
    "print('precision score',precision_score(y_test,test_predictions))\n",
    "print('recall score',recall_score(y_test,test_predictions))\n",
    "print('test f1_score :',f1_score(y_test,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score 0.8651685393258427\n",
      "recall score 0.7857142857142857\n",
      "train f1_score : 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "#train scores\n",
    "print('precision score',precision_score(y_train,train_predictions))\n",
    "print('recall score',recall_score(y_train,train_predictions))\n",
    "print('train f1_score :',f1_score(y_train,train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive rate')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.ylabel('True Positive rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272667456244244"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of variables which zero down: 231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficients\n",
       "0             0.0\n",
       "1             0.0\n",
       "2            -0.0\n",
       "3             0.0\n",
       "4            -0.0\n",
       "..            ...\n",
       "227           0.0\n",
       "228          -0.0\n",
       "229          -0.0\n",
       "230           0.0\n",
       "231           0.0\n",
       "\n",
       "[232 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha = 0.05)\n",
    "lasso.fit(X_train_final,y_train)\n",
    "lasso_coef_df = pd.DataFrame({'coefficients':lasso.coef_})\n",
    "print('No. of variables which zero down:',len(lasso_coef_df[lasso_coef_df['coefficients']==0]))\n",
    "lasso_coef_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>-0.007556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-0.016873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-0.098363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-0.127924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.129153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficients\n",
       "0        0.004947\n",
       "1       -0.012561\n",
       "2       -0.015142\n",
       "3        0.006474\n",
       "4        0.001451\n",
       "..            ...\n",
       "227     -0.007556\n",
       "228     -0.016873\n",
       "229     -0.098363\n",
       "230     -0.127924\n",
       "231      0.129153\n",
       "\n",
       "[232 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 1.0)\n",
    "ridge.fit(X_train_final,y_train)\n",
    "ridge_coef_df = pd.DataFrame({'coefficients':ridge.coef_})\n",
    "len(ridge_coef_df[ridge_coef_df['coefficients']==0])\n",
    "ridge_coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train_final,y_train)\n",
    "dt_predictions = dtc.predict(X_test_final)\n",
    "dt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  22],\n",
       "       [ 24,  27]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree precision score 0.5510204081632653\n",
      "decision tree recall score 0.5294117647058824\n",
      "decision tree f1_score : 0.54\n",
      "decision tree roc_auc_score 0.6908803789972364\n"
     ]
    }
   ],
   "source": [
    "print('decision tree precision score',precision_score(y_test,dt_predictions))\n",
    "print('decision tree recall score',recall_score(y_test,dt_predictions))\n",
    "print('decision tree f1_score :',f1_score(y_test,dt_predictions))\n",
    "print('decision tree roc_auc_score',roc_auc_score(y_test,dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_final,y_train)\n",
    "rf_predictions = rfc.predict(X_test_final)\n",
    "rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest precision score 0.4827586206896552\n",
      "random_forest recall score 0.27450980392156865\n",
      "random_forest f1_score : 0.3500000000000001\n",
      "random forest roc_auc_score 0.5869193314909856\n"
     ]
    }
   ],
   "source": [
    "print('random_forest precision score',precision_score(y_test,rf_predictions))\n",
    "print('random_forest recall score',recall_score(y_test,rf_predictions))\n",
    "print('random_forest f1_score :',f1_score(y_test,rf_predictions))\n",
    "print('random forest roc_auc_score',roc_auc_score(y_test,rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning for Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [5, 6, 7, 8, 9],\n",
       "                         'max_leaf_nodes': [4, 5, 6, 7, 8],\n",
       "                         'min_samples_leaf': [6, 7, 8, 9, 10],\n",
       "                         'min_samples_split': [5, 6, 7, 8, 9]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_dtc_dict = {\n",
    "               'max_depth':[5,6,7,8,9],\n",
    "               'min_samples_split':[5,6,7,8,9],\n",
    "               'max_leaf_nodes':[4,5,6,7,8],\n",
    "               'min_samples_leaf':[6,7,8,9,10]\n",
    "              }\n",
    "gcv_dtc=GridSearchCV(dtc,hp_dtc_dict,cv=5,scoring='f1')\n",
    "gcv_dtc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  DecisionTreeClassifier(max_depth=5, max_leaf_nodes=4, min_samples_leaf=6,\n",
      "                       min_samples_split=5)\n",
      "the best score is  0.7595474425042728\n",
      "the best parameters are  {'max_depth': 5, 'max_leaf_nodes': 4, 'min_samples_leaf': 6, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',gcv_dtc.best_estimator_)\n",
    "print('the best score is ',gcv_dtc.best_score_)\n",
    "print('the best parameters are ',gcv_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_dtc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=500,\n",
       "                   param_distributions={'max_depth': [5, 6, 7, 8, 9],\n",
       "                                        'max_leaf_nodes': [4, 5, 6, 7, 8],\n",
       "                                        'min_samples_leaf': [6, 7, 8, 9, 10],\n",
       "                                        'min_samples_split': [5, 6, 7, 8, 9]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_dtc=RandomizedSearchCV(dtc,hp_dtc_dict,cv=5,scoring='f1',n_iter=500)\n",
    "rdcv_dtc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_dtc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  DecisionTreeClassifier(max_depth=9, max_leaf_nodes=4, min_samples_leaf=7,\n",
      "                       min_samples_split=9)\n",
      "the best score is  0.7595474425042728\n",
      "the best parameters are  {'min_samples_split': 9, 'min_samples_leaf': 7, 'max_leaf_nodes': 4, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',rdcv_dtc.best_estimator_)\n",
    "print('the best score is ',rdcv_dtc.best_score_)\n",
    "print('the best parameters are ',rdcv_dtc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [5, 6, 7, 8],\n",
       "                         'max_leaf_nodes': [5, 6, 7, 8],\n",
       "                         'min_samples_leaf': [7, 8, 9, 10],\n",
       "                         'min_samples_split': [6, 7, 8, 9],\n",
       "                         'n_estimators': [50, 100, 150, 200]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_rfc_dict= {\n",
    "              'max_depth':[5,6,7,8],\n",
    "               'min_samples_split':[6,7,8,9],\n",
    "               'max_leaf_nodes':[5,6,7,8],\n",
    "               'min_samples_leaf':[7,8,9,10],\n",
    "               'n_estimators':[50,100,150,200]\n",
    "             }\n",
    "gcv_rfc = GridSearchCV(rfc,hp_rfc_dict,cv=4,scoring='f1')\n",
    "gcv_rfc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  RandomForestClassifier(max_depth=6, max_leaf_nodes=8, min_samples_leaf=7,\n",
      "                       min_samples_split=6, n_estimators=50)\n",
      "the best score is  0.07767722473604825\n",
      "the best parameters are  {'max_depth': 6, 'max_leaf_nodes': 8, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',gcv_rfc.best_estimator_)\n",
    "print('the best score is ',gcv_rfc.best_score_)\n",
    "print('the best parameters are ',gcv_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_rfc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomizedsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=500,\n",
       "                   param_distributions={'max_depth': [5, 6, 7, 8],\n",
       "                                        'max_leaf_nodes': [5, 6, 7, 8],\n",
       "                                        'min_samples_leaf': [7, 8, 9, 10],\n",
       "                                        'min_samples_split': [6, 7, 8, 9],\n",
       "                                        'n_estimators': [50, 100, 150, 200]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_rfc= RandomizedSearchCV(rfc,hp_rfc_dict,cv=3,n_iter=500,scoring='f1')\n",
    "rdcv_rfc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_rfc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  RandomForestClassifier(max_depth=8, max_leaf_nodes=8, min_samples_leaf=9,\n",
      "                       min_samples_split=6, n_estimators=50)\n",
      "the best score is  0.06626425217974515\n",
      "the best parameters are  {'n_estimators': 50, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_leaf_nodes': 8, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',rdcv_rfc.best_estimator_)\n",
    "print('the best score is ',rdcv_rfc.best_score_)\n",
    "print('the best parameters are ',rdcv_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train_final,y_train)\n",
    "ab_predictions = abc.predict(X_test_final)\n",
    "ab_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  22],\n",
       "       [ 24,  27]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,ab_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost precision score 0.5476190476190477\n",
      "Adaboost recall score 0.45098039215686275\n",
      "Adaboost f1_score : 0.49462365591397855\n",
      "Adaboost roc_auc_score 0.6617318068166863\n"
     ]
    }
   ],
   "source": [
    "print('Adaboost precision score',precision_score(y_test,ab_predictions))\n",
    "print('Adaboost recall score',recall_score(y_test,ab_predictions))\n",
    "print('Adaboost f1_score :',f1_score(y_test,ab_predictions))\n",
    "print('Adaboost roc_auc_score',roc_auc_score(y_test,ab_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning - Adaboost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostClassifier(),\n",
       "             param_grid={'learning_rate': [0.5, 1.0, 1.5],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_abc_dict ={\n",
    "              'n_estimators':[50,100,150],\n",
    "              'learning_rate':[0.5,1.0,1.5]\n",
    "            }\n",
    "gcv_abc = GridSearchCV(abc,hp_abc_dict,cv=5,scoring = 'f1')\n",
    "gcv_abc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_abc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  AdaBoostClassifier()\n",
      "f1 score is  0.5768052640165316\n",
      "the best parameters are  {'learning_rate': 1.0, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',gcv_abc.best_estimator_)\n",
    "print('f1 score is ',gcv_abc.best_score_)\n",
    "print('the best parameters are ',gcv_abc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=AdaBoostClassifier(), n_iter=100,\n",
       "                   param_distributions={'learning_rate': [0.5, 1.0, 1.5],\n",
       "                                        'n_estimators': [50, 100, 150]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_abc=RandomizedSearchCV(abc,hp_abc_dict,cv=3,scoring='f1',n_iter=100)\n",
    "rdcv_abc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_abc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  AdaBoostClassifier()\n",
      "the best score is  0.5708390935663664\n",
      "the best parameters are  {'n_estimators': 50, 'learning_rate': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',rdcv_abc.best_estimator_)\n",
    "print('the best score is ',rdcv_abc.best_score_)\n",
    "print('the best parameters are ',rdcv_abc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train_final,y_train)\n",
    "gb_predictions = gbc.predict(X_test_final)\n",
    "gb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  22],\n",
       "       [ 17,  34]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,gb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boost precision score 0.6071428571428571\n",
      "Gradient boost recall score 0.6666666666666666\n",
      "Gradient boost f1_score : 0.6355140186915887\n",
      "Gradient boost roc_auc_score 0.7595078299776286\n"
     ]
    }
   ],
   "source": [
    "print('Gradient boost precision score',precision_score(y_test,gb_predictions))\n",
    "print('Gradient boost recall score',recall_score(y_test,gb_predictions))\n",
    "print('Gradient boost f1_score :',f1_score(y_test,gb_predictions))\n",
    "print('Gradient boost roc_auc_score',roc_auc_score(y_test,gb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning- Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.3],\n",
       "                         'max_depth': [5, 6, 7, 8],\n",
       "                         'max_leaf_nodes': [5, 6, 7, 8],\n",
       "                         'min_samples_leaf': [7, 8, 9, 10],\n",
       "                         'min_samples_split': [6, 7, 8, 9],\n",
       "                         'n_estimators': [50, 100, 150, 200]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "hp_gbc_dict = {\n",
    "               'max_depth':[5,6,7,8],\n",
    "               'min_samples_split':[6,7,8,9],\n",
    "               'max_leaf_nodes':[5,6,7,8],\n",
    "               'min_samples_leaf':[7,8,9,10],\n",
    "               'n_estimators':[50,100,150,200],\n",
    "               'learning_rate':[0.1,0.2,0.3]\n",
    "              }\n",
    "gcv_gbc=GridSearchCV(gbc,hp_gbc_dict,cv=3,scoring='f1')\n",
    "gcv_gbc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv_gbc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  GradientBoostingClassifier(max_depth=5, max_leaf_nodes=5, min_samples_leaf=10,\n",
      "                           min_samples_split=6, n_estimators=50)\n",
      "the f1 score is  0.7131671947668302\n",
      "the best parameters are  {'learning_rate': 0.1, 'max_depth': 5, 'max_leaf_nodes': 5, 'min_samples_leaf': 10, 'min_samples_split': 6, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',gcv_gbc.best_estimator_)\n",
    "print('the f1 score is ',gcv_gbc.best_score_)\n",
    "print('the best parameters are ',gcv_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.2, 0.3],\n",
       "                                        'max_depth': [5, 6, 7, 8],\n",
       "                                        'max_leaf_nodes': [5, 6, 7, 8],\n",
       "                                        'min_samples_leaf': [7, 8, 9, 10],\n",
       "                                        'min_samples_split': [6, 7, 8, 9],\n",
       "                                        'n_estimators': [50, 100, 150, 200]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_gbc=RandomizedSearchCV(gbc,hp_gbc_dict,cv=3,scoring='f1',n_iter=100)\n",
    "rdcv_gbc.fit(X_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_gbc.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  GradientBoostingClassifier(max_depth=7, max_leaf_nodes=5, min_samples_leaf=8,\n",
      "                           min_samples_split=9, n_estimators=50)\n",
      "the f1 score is  0.7122877515257718\n",
      "the best parameters are  {'n_estimators': 50, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_leaf_nodes': 5, 'max_depth': 7, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',rdcv_gbc.best_estimator_)\n",
    "print('the f1 score is ',rdcv_gbc.best_score_)\n",
    "print('the best parameters are ',rdcv_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1.0,kernel='linear')\n",
    "svm.fit(X_train_final,y_train)\n",
    "svm_predicts = svm.predict(X_test_final)\n",
    "svm_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139,  10],\n",
       "       [ 41,  10]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,svm_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support vector machine precision score 0.66\n",
      "support vector machine recall score 0.6470588235294118\n",
      "support vector machine f1_score : 0.6534653465346535\n",
      "support vector machine roc_auc_score 0.7664824318989341\n"
     ]
    }
   ],
   "source": [
    "print('support vector machine precision score',precision_score(y_test,svm_predicts))\n",
    "print('support vector machine recall score',recall_score(y_test,svm_predicts))\n",
    "print('support vector machine f1_score :',f1_score(y_test,svm_predicts))\n",
    "print('support vector machine roc_auc_score',roc_auc_score(y_test,svm_predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_svm_dict = {\n",
    "               'C':[0.6,0.8,1.0],\n",
    "               'kernel':['linear', 'poly', 'rbf', 'sigmoid']\n",
    "              }\n",
    "gcv_svm = GridSearchCV(svm,hp_svm_dict,cv=3,scoring='f1')\n",
    "gcv_svm.fit(X_train_final,y_train)\n",
    "svm_predicts = gcv_svm.predict(X_test_final)\n",
    "svm_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  SVC(C=0.6, kernel='linear')\n",
      "the f1 score is  0.6134925136626782\n",
      "the best parameters are  {'C': 0.6, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',gcv_svm.best_estimator_)\n",
    "print('the f1 score is ',gcv_svm.best_score_)\n",
    "print('the best parameters are ',gcv_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdcv_svm = RandomizedSearchCV(svm,hp_svm_dict,cv=3,scoring='f1',n_iter=100)\n",
    "rdcv_svm.fit(X_train_final,y_train)\n",
    "rdcv_svm.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best estimates for the parameters are  SVC(C=0.6, kernel='linear')\n",
      "the f1 score is  0.6134925136626782\n",
      "the best parameters are  {'kernel': 'linear', 'C': 0.6}\n"
     ]
    }
   ],
   "source": [
    "print('the best estimates for the parameters are ',rdcv_svm.best_estimator_)\n",
    "print('the f1 score is ',rdcv_svm.best_score_)\n",
    "print('the best parameters are ',rdcv_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
